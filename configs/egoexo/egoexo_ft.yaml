pretrain: "./models/vit-16-32f.pt"
resume:
seed: 1024
data:
    dataset: egoexo
    modality: RGB
    num_frames: 16 
    ds: [24]
    ol: [1]
    seg_length: 1
    split: 1 # pretty sure this does not do anything
    batch_size: 25
    workers: 32
    gpus: 2
    num_classes: 326 # TODO: Check the number of classes here. For now I am hard coding this.
    index_bias: 1
    input_size: 224
    n_split: 1 # MAKE SURE TO CHAMGE THIS
    max_act: 8  # TODO: play with this parameter
    randaug:
        N: 0 #2
        M: 0  #9
network:
    arch: ViT-B/16  #ViT-B/32 ViT-B/16
    init: True # scratch, imagenet, kinetics
    drop_out: 0.0 # probability of an element to be zeroed
    emb_dropout: 0.0 # probability of embedding to be zeroed
    partial_bn: False
    version: ''
    bn_momentum: 0.1
    consensus_type: avg
    type: clip_ucf
    sim_header: 'Transf'  #Transf   meanP   LSTM   Transf_cls Conv_1D
    fix_text: False
    fix_img: False
    describe:
solver:
    type: cosine
    epochs: 50
    start_epoch: 0
    epoch_offset: 0
    optim: adamw
    lr: 5.e-6
    lr_warmup_step: 5
    momentum: 0.9
    weight_decay: 0.2
    lr_decay_step: 15
    lr_decay_factor: 0.1
    clip_gradient: 20
    loss_type: nll
    evaluate: False
    ratio: 1
    f_ratio: 10
    r_actloss: 1
logging:
    print_freq: 10
    eval_freq: 1